{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "crew_df = pd.read_csv('../dataset/crew.csv', low_memory=False)\n",
    "actors_df = pd.read_csv('../dataset/actors.csv', low_memory=False)\n",
    "genres_df = pd.read_csv('../dataset/genres.csv', low_memory=False)\n",
    "languages_df = pd.read_csv('../dataset/languages.csv', low_memory=False)\n",
    "movies_df = pd.read_csv('../dataset/movies.csv', low_memory=False)\n",
    "posters_df = pd.read_csv('../dataset/posters.csv', low_memory=False)\n",
    "ratings_df = pd.read_csv('../dataset/ratings.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'name', 'date', 'tagline', 'description', 'minute', 'rating'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(movies_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratings Based Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x140884d10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ratings-Based Recommendation\n",
    "# Load and prepare data\n",
    "reader = Reader(rating_scale=(ratings_df['rating'].min(), ratings_df['rating'].max()))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split data and train SVD model\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "svd = SVD()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie ID: 1179808, Title: Accidents, Blunders and Calamities, Rating: nan\n",
      "Movie ID: 1043156, Title: Outfoxed: Rupert Murdoch's War on Journalism, Rating: 3.36\n",
      "Movie ID: 1442438, Title: Il Diario di Sisifo, Rating: nan\n",
      "Movie ID: 1128365, Title: REM, Rating: nan\n",
      "Movie ID: 1515400, Title: Sweet Tooth, Rating: nan\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import ast\n",
    "user_id = 3\n",
    "\n",
    "if ratings_df.size > 0:\n",
    "    # Get all movie IDs in the dataset\n",
    "    all_movie_ids = ratings_df['movieId'].unique()\n",
    "\n",
    "    # Filter out movies the user has already rated\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId']\n",
    "    unrated_movies = [movie for movie in all_movie_ids if movie not in rated_movies.values]\n",
    "\n",
    "    # Predict ratings for each unrated movie\n",
    "    predictions = [(movie_id, svd.predict(user_id, movie_id).est) for movie_id in unrated_movies]\n",
    "    sorted_predictions = sorted(predictions, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    predicted_ratings_df = pd.DataFrame(predictions, columns=['movie_id', 'rating']).set_index('movie_id')\n",
    "\n",
    "    # Step 5: Get Top 5 Recommendations with Valid Titles\n",
    "    top_5_recommendations = []\n",
    "    for movie_id, predicted_rating in sorted_predictions:\n",
    "        # Retrieve title\n",
    "        title = movies_df[movies_df['id'] == str(movie_id)]['title']\n",
    "        genre = movies_df[movies_df['id'] == str(movie_id)]['genres']\n",
    "        cast = actors_df[actors_df['id'] == movie_id]['cast']\n",
    "        poster = movies_df[movies_df['id'] == str(movie_id)]['poster_path']\n",
    "\n",
    "        names = []\n",
    "        for g in genre:\n",
    "            g = ast.literal_eval(g)\n",
    "            for n in g:\n",
    "                names.append(n['name'])\n",
    "        \n",
    "        # Check if the title exists and is not empty\n",
    "        if not title.empty:\n",
    "            top_5_recommendations.append((movie_id, title.values[0], predicted_rating, names, cast, poster))\n",
    "        \n",
    "        # Stop once we have 5 valid recommendations\n",
    "        if len(top_5_recommendations) == 5:\n",
    "            break\n",
    "\n",
    "    # Display recommended movie IDs, titles, and predicted ratings\n",
    "    print(\"Top 5 Recommended Movies (movie_id, title, predicted_rating):\")\n",
    "    for movie_id, title, predicted_rating, genres, cast, poster in top_5_recommendations:\n",
    "        print(f\"Movie ID: {movie_id}, Movie Name: {title}, Predicted Rating: {round(predicted_rating, 2)}, Genres: {genres}\")\n",
    "        print(f\"Cast: {cast}, Poster: {poster}\")\n",
    "else:\n",
    "    top_5_recommendations = movies_df.sample(n=5).values.tolist()\n",
    "    for movie in top_5_recommendations:\n",
    "        print(f\"Movie ID: {movie[0]}, Title: {movie[1]}, Rating: {movie[6]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genre_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Standardize the content-based similarity scores for easier combination\u001b[39;00m\n\u001b[1;32m      3\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 4\u001b[0m genre_similarity_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(genre_similarity)\n\u001b[1;32m      5\u001b[0m keyword_similarity_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(keyword_similarity)\n\u001b[1;32m      6\u001b[0m actor_similarity_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(actor_similarity)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genre_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize the content-based similarity scores for easier combination\n",
    "scaler = StandardScaler()\n",
    "genre_similarity_scaled = scaler.fit_transform(genre_similarity)\n",
    "keyword_similarity_scaled = scaler.fit_transform(keyword_similarity)\n",
    "actor_similarity_scaled = scaler.fit_transform(actor_similarity)\n",
    "\n",
    "# Define weights for each component\n",
    "weight_collab = 0.5\n",
    "weight_genre = 0.2\n",
    "weight_keyword = 0.2\n",
    "weight_actor = 0.1\n",
    "\n",
    "# Create a final recommendation score for each movie by combining weighted scores\n",
    "def hybrid_recommend(user_id, top_n=5):\n",
    "    # Retrieve collaborative filtering predictions for this user\n",
    "    user_predictions = predicted_ratings_df['rating']\n",
    "    \n",
    "    # Compute weighted hybrid scores for each movie\n",
    "    hybrid_scores = (weight_collab * user_predictions +\n",
    "                     weight_genre * genre_similarity_scaled[user_id] +\n",
    "                     weight_keyword * keyword_similarity_scaled[user_id] +\n",
    "                     weight_actor * actor_similarity_scaled[user_id])\n",
    "    \n",
    "    # Sort and get the top N recommended movie IDs\n",
    "    top_movie_indices = np.argsort(hybrid_scores)[::-1][:top_n]\n",
    "    top_movies = movies_metadata_df.iloc[top_movie_indices]\n",
    "    \n",
    "    # Display the recommendations\n",
    "    print(\"Top Recommended Movies:\")\n",
    "    for index, row in top_movies.iterrows():\n",
    "        print(f\"Title: {row['title']}, Hybrid Score: {hybrid_scores[index]}\")\n",
    "\n",
    "# Example recommendation for a specific user\n",
    "hybrid_recommend(user_id=1, top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
